name: Test Local Setup (Linux)

on:
  push:
    branches: [main, develop]
    paths:
      - 'docker-compose.yml'
      - 'scripts/setup-local-env.sh'
      - 'scripts/test-local-setup.sh'
      - 'schemas/samples/generate_sample_data.py'
      - '.github/workflows/test-local-setup.yml'
  pull_request:
    branches: [main, develop]
  workflow_dispatch:  # Allow manual triggering
  # schedule:  # Uncomment when ready for weekly runs
  #   - cron: '0 6 * * 1'  # Mondays at 6 AM UTC

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  test-local-setup:
    name: Test Local Setup on Ubuntu
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Free up disk space
        run: |
          # GitHub runners have limited space, clean up to make room
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo docker system prune -af
          df -h

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y python3 python3-pip curl
          python3 --version
          docker --version
          docker compose version

      - name: Start Gridata services
        run: |
          echo "ğŸš€ Starting Gridata local environment..."

          # Make scripts executable
          chmod +x scripts/setup-local-env.sh
          chmod +x scripts/test-local-setup.sh

          # Create required directories
          mkdir -p schemas/samples
          mkdir -p airflow/logs

          # Start Docker Compose services
          docker compose up -d

          # Give services a moment to start
          sleep 10

          # Show what's running
          echo "ğŸ“Š Initial container status:"
          docker compose ps

      - name: Wait for core services
        timeout-minutes: 15
        run: |
          echo "â³ Waiting for services to be ready..."

          # Wait for PostgreSQL first (others depend on it)
          echo "Checking PostgreSQL..."
          for i in {1..60}; do
            if docker exec gridata-postgres pg_isready -U gridata -h localhost 2>/dev/null; then
              echo "âœ… PostgreSQL is ready"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "âš ï¸  PostgreSQL taking longer than expected, checking logs..."
              docker logs gridata-postgres --tail 20
            fi
            echo "  Attempt $i/60: Waiting for PostgreSQL..."
            sleep 5
          done

          # Wait for MinIO
          echo "Checking MinIO..."
          for i in {1..30}; do
            if curl -f http://localhost:9000/minio/health/live 2>/dev/null; then
              echo "âœ… MinIO is ready"
              break
            fi
            echo "  Attempt $i/30: Waiting for MinIO..."
            sleep 5
          done

          # Wait for Airflow (needs PostgreSQL)
          echo "Checking Airflow..."
          for i in {1..90}; do
            if curl -f http://localhost:8080/health 2>/dev/null; then
              echo "âœ… Airflow is ready"
              break
            fi
            if [ $i -eq 60 ]; then
              echo "âš ï¸  Airflow taking longer than expected, checking logs..."
              docker logs gridata-airflow-webserver --tail 30
            fi
            echo "  Attempt $i/90: Waiting for Airflow..."
            sleep 5
          done

      - name: Check service status
        run: |
          echo "ğŸ“Š Service Status:"
          docker compose ps

          echo ""
          echo "ğŸ“Š Container Health:"
          docker ps --format "table {{.Names}}\t{{.Status}}"

      - name: Generate sample data
        run: |
          echo "ğŸ“Š Generating sample data..."
          cd schemas/samples
          pip3 install faker pandas pyarrow
          python3 generate_sample_data.py
          ls -lh *.parquet *.jsonl 2>/dev/null || echo "Data files created"
          cd ../..

      - name: Upload sample data to MinIO
        run: |
          echo "â¬†ï¸  Uploading sample data to MinIO..."

          docker run --rm --network gridata-network \
            -v $(pwd)/schemas/samples:/data \
            minio/mc:latest sh -c "
            mc alias set local http://minio:9000 minioadmin minioadmin123 && \
            mc ls local/ && \
            mc cp /data/orders.jsonl local/gridata-raw/raw/ecommerce/orders/2024-01-01/ || true && \
            mc cp /data/customers.parquet local/gridata-raw/raw/ecommerce/customers/ || true && \
            mc cp /data/products.parquet local/gridata-raw/raw/ecommerce/products/ || true && \
            mc cp /data/clickstream.parquet local/gridata-raw/raw/ecommerce/clickstream/ || true
          "

      - name: Run health checks
        run: |
          echo "ğŸ§ª Running health checks..."

          # Test MinIO
          curl -f http://localhost:9000/minio/health/live || echo "MinIO health check failed"

          # Test Airflow
          curl -f http://localhost:8080/health || echo "Airflow health check failed"

          # Test Spark UI
          curl -f http://localhost:8081 || echo "Spark UI check failed"

          # Check containers
          docker compose ps

      - name: Test Airflow DAGs
        run: |
          echo "ğŸŒ¬ï¸  Testing Airflow DAGs..."
          docker exec gridata-airflow-webserver airflow dags list || echo "DAG list failed"

      - name: Test MinIO buckets
        run: |
          echo "ğŸª£ Testing MinIO buckets..."
          docker exec gridata-minio mc ls local/ || echo "MinIO bucket list failed"

      - name: View logs on failure
        if: failure()
        run: |
          echo "ğŸ“‹ Docker Compose Services:"
          docker compose ps

          echo ""
          echo "ğŸ“‹ MinIO Logs:"
          docker compose logs --tail=100 minio

          echo ""
          echo "ğŸ“‹ PostgreSQL Logs:"
          docker compose logs --tail=100 postgres

          echo ""
          echo "ğŸ“‹ Airflow Webserver Logs:"
          docker compose logs --tail=100 airflow-webserver

          echo ""
          echo "ğŸ“‹ Spark Master Logs:"
          docker compose logs --tail=100 spark-master

      - name: Cleanup
        if: always()
        run: |
          echo "ğŸ§¹ Cleaning up..."
          docker compose down -v
          docker system prune -f
